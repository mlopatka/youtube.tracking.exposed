---
title: "1st Global coordinated observation of the Youtube algorithm"
subtitle: "Only by compare how AI mistreat you and others, we can grasp how this is a collective issue"
draft: false
date: 2020-03-01T10:26:08Z

og_title: "1st Global collaborative analysis of Youtube Algorithm"
og_type: "website"
og_image: "http://youtube.tracking.exposed/images/compare.jpeg"
og_url: "https://youtube.tracking.exposed/wetest/1"
og_description: "This is the first worldwide test of the Youtube algorithm; on Sunday March 15th, with a browser extension, we'll see how YT personalizes the customer experience"

extraCSS: "/css/wetest.css"
---

<script src="/js/collaborative-tests.js"></script>

<div class="container col-12 justify-content-center">
  <h1 style="text-align:center;">Experiment — 25 of March 2020 — in
    <span class="project-color"> <span id="demo"></span> </span>
   </h1>
</div>

<div class="container row">
  <img width="48%" class="align-right imgtile" src="/images/youtrust.svg" />
  <img width="48%" class="align-right imgtile" src="/images/wetest-know.svg" />
</div>

<br>
{{<colorblock text="a 10 minutes experiment where every contribution matters.">}}
<br>

<div class="container col-12 justify-content-center">
  <h2 class="project-color">FIRST ― To save personalization's evidences join us: </h2>
  {{<yt-extension>}}
</div>

{{<colorblock >}}
<br>

<div class="container col-12 justify-content-center">
  <h2 class="project-color">SECOND ― Follow the links, the order matters!</h2>

  <small>The links will be declared few hours before launching the test!</small>
  <div class="test-steps links--disabled">
    <ol>
      <li>
        Open <a href="https://www.youtube.com" target="_blank">YouTube Homepage</a>.
      </li>
      <li>
        Watch The first video: <a href="https://www.youtube.com/watch?v=" target="_blank">Which is still to be defined!</a>!.
      </li>
      <li>
        Watch The second video: <a href="https://www.youtube.com/watch?v=" target="_blank">Which is still to be defined!</a>!.
      </li>
      <li>
        Watch The third video: <a href="https://www.youtube.com/watch?v=" target="_blank">Which is still to be defined!</a>!.
      </li>
      <li>
        Watch The fourth video: <a href="https://www.youtube.com/watch?v=" target="_blank">Which is still to be defined!</a>!.
      </li>
      <li>
        Open againg <a href="https://www.youtube.com" target="_blank">YouTube Homepage </a> 
      </li>
    </ol>
    <small>Why have we <a href="/wetest/announcement-1#on-experiment-design">organized the test this way</a>?</small>
    <br>
    <br>
  </div>

</div> <!-- container -->

{{<colorblock >}}

<div class="container col-12 justify-content-center">
  <br>
  <h2 class="project-color">THIRD ― Compare, analyze, understand</h2>
  <br>

  <div class="row enlarged">
    <div class="col-4">
      We'll release the data, properly anonymized, for public analysis, 
      <a href="/wetest/announcement-1">Here you'll find releases and updates</a>.
    </div>
    <div class="col-4">
      If you produce findings or visualization, we'll be glad to include yours, so please <a href="https://chat.securitywithoutborders.org/community/channels/trackingexposed">reach out in our mattermost chat</a>.
    </div>
    <div class="col-4">
      We'll share soon an expected timeline of releases and we'll keep
        <a href="/wetest/announcement-1">updating this page</a>.
    </div>
  </div> 

</div> <!-- container -->

<br>
{{<colorblock >}}

<div class="container col-12 justify-content-center">
  <br>
  <h2 class="project-color">EXTRA ― Know more about us and the design of the test and what should happen next</h2>
  <br>
  <div class="row enlarged">
    <div class="col-6">
      <h3>weTEST Experiment Design</h3>
      <p>Testing a personalization algorithm isn't quick and straightforward, as it seems. The researcher has to define a methodology. This method gives different values to the collected samples because they are only useful to test the assumptions initially made. 
        <br>
        <br>

        <i>This text explores a difficult concept. It might take a while before fully interiorize the complexity of tools, restrictions, and variables tracking. If anything is unclear, don't miss the
          <a href="/automation"><b>
            three different methodologies lead to different dataset properties
          </b></a>,
          <a href="/what-we-collect"><b>
            what we collect and how data might be safely released
          </b> </a>, and 
          <a href="/data"><b>
            data format and usages
          </b></a>.
        </i>
        <br>
        <br>
        Because wetest wants to be a collaborative experiment, it is smart to develop initial findings without assuming any past research. We'll start with a few concise research questions. 
        <br>
        Inevitability, at the beginning, these question are more technical than focused on studying the political impact of the recommendation algorithms. In this initial phase we focus on developing tools and best practices. 
        <br>
        <br>
        Tracking.exposed goals aren't merely to produce reports, articles, or researches. Yes, we do it, (look at our <a href="/">home</a>, bottom-left); it has been part of our training experience. Algorithm accountability can't be revolutionary if accessible only to data analyst and data protection authority. A bit of knowledge on platform influence, or algorithm literacy, should be in the modern background education, and we want to play with it. 
        <br>
        <br>
        Do you remember, companies taking a bunch of random users and experiment on them? 
          <b>We'll do precisely the opposite</b>: 
          <b>a distributed crowd of random individuals, coordinated to experiment on them!</b>
          Anyone can contribute. Someone with a clean, freshly installed browser, someone else with their Google account logged. Partecipants, during the chosen day, should watch a few videos, and we'll collect the video the platform will recommend. We will run analysis to see how much diverse ends up to be suggested video. 
          <br<br>
          It is the most basic calculus on how much is unique, personalized, the experience the company decide for us.
      </p>

    </div>
    <div class="col-6">
      <img class="imgtile" width="96%" style="margin-left:2%;margin-right:2%" src="/images/wetest-youralgo.svg" />
      <br>
      <smaller style="font-size:0.6em;">This is our 
        <a href="https://tracking.exposed/manifesto">Manifesto </a>, or checkout the 
        <a href="https://pornhub.tracking.exposed/potest/final-1">collaborative PornHub analysis</a>, and
        <a href="/preview">use ytTREX</a>.
      </smaller>
      <br>
      <h3>This test - why language?</h3>
      <blockquote class="blockquote">
        <p class="mb-0">
          Farshad Shadloo, a YouTube spokesman, said the company’s recommendations aimed to steer people toward authoritative videos that leave them satisfied. He said the company was continually improving the algorithm that generates the recommendations. “Over the past year alone, we’ve launched over 30 different changes to reduce recommendations of borderline content and harmful misinformation, including climate change misinformation and other types of conspiracy videos,” he said. “Thanks to this change, watchtime this type of content gets from recommendations has dropped by over 70 percent in the U.S.”
        </p>
        <footer class="blockquote-footer" style="margin-top:0;border-top:0;">NYTimes 2 March 2020
          <cite title="Source Title">Can YouTube Quiet Its Conspiracy Theorists?</cite>
        </footer>
      </blockquote>
      <p>
        In commentary such as the one above, there are two pitfalls: <b>a language issue</b>, and a <b>trust issue</b>.
        <br>
        Maybe YT is right, and in English language, for the US audience, Youtube investment might guarantee a quality in content curaction high enough to avoid fines, but would be that true in another language? 
        <br>
        The exploitative business model of surveillance capitalism can't easily scale when the succes metric is the _removal of content troublesome for a precise culture_ because investing in content moderator trained and balanced in every culture in the world seems unfeasable due to high costs.
        <br>
        This first experiment concentrate effort in watching four videos chosen by us, on the same broad topic (covid19), in the four most used langagues in the world.
        <br>
        Regardless of trust, how is credible a company who promise changes, (they are invisible), and the quality assessment of such improvements comes from the same organization? Independent testing, like the one we want to enable, is an option accessible to you, to a class of students, to the FTC and to the DPAs.
      </p>
    </div>
  </div> 

  <h3>
    We want to apply the most scientific, open, distributed approach we can aim for
  </h3>
  <p>
    <b>
      Diversity is the key
    </b>, but how exactly?
    <br>
    <br>
    Personalization algorithms, content curation, and targeted experiences are unique for each of us. 
    <br>
    Winning the fight for algorithmic independence (when you retain agency and control on the prioritization filter know as recommendation system), make sense if most of us reach that point. A minority of techno elite, literate enough to fact-check and with the skills to find the right information online, would only reinforce inequality among the people in the information age. Diversity is the key because we collectively should understand how other people are perceiving the public discourse. 
    <br>
    A widely deployed recommendation system should be validated by a public policy. It should be subject to public scrutiny, gauging the impact on all of us. Just in 2020, the goal is not a better society but a fluid business flow in the monopolist's hand.
    <br>
    Algorithm analysis might seems a purely technical effort. But the platform we're operating on (Facebook, youtube, amazon) mixes social constructs with their technology, and implicitly, the limited form of algorithm analysis we can perform via passive observation, inherit complexities typical of political analysis.
    <br>
    <br>
    Now, with wetest#1, <b>we begin with the technical analysis</b>, to build up a knowledge base robust enough to address <b>political and sociological analysis</b>. We can't yet address research questions such as "<i>Does youtube radicalize or not people?</i>" or "<i>are videos with blonde white women prioritized against other demographics? It is true in any region?</i>". We want to coordinate tests with these politically meaningful topics, but we can't yet, they aren't low hanging fruits. Releasing approximative analysis would be detrimental for algorithm literacy and platform accountability. Let's build this community with academics and digital rights defender. 
    <br>
    If you have an idea, propose your experiment by
    <a href="https://github.com/tracking-exposed/youtube.tracking.exposed/issues/new?assignees=&labels=research+question&template=research-question-proposal.md&title=%3CRQ%3E" target=_blank>opening this formatted GitHub issue</a>
    , and please consider:
    <ol>
      <li>we should start to measure technical conditions, and be confident in testing such variables.</li>
      <li>read other issues marked in the same way; this might help to understand which limits this test has.</li>
      <li>research questions should come from the community: concerned citizen, seasoned professional expert, to submit a proposal open a GitHub issue in our repository.</li>
    </ol>
  </p>

</div> <!-- container -->

<script>
  $(document).ready(function() {
    countdown(new Date("Mar 25, 2020 00:00:01"), "demo");
  });
</script>
